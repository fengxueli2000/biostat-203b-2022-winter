---
title: "Biostat 203B Homework 4"
subtitle: Due Mar 18 @ 11:59PM
output:
  # ioslides_presentation: default
  html_document:
    toc: true
    toc_depth: 4
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

Display machine information:
```{r}
sessionInfo()
```
Load database libraries and the tidyverse frontend:
```{r}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(miceRanger))
```

## Q1. Missing data

Through the Shiny app developed in HW3, we observe abundant missing values in the MIMIC-IV ICU cohort we created. In this question, we use multiple imputation to obtain a data set without missing values.

0. Read following tutorials on the R package miceRanger for imputation: <https://github.com/farrellday/miceRanger>, <https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html>.

    A more thorough book treatment of the practical imputation strategies is the book [*_Flexible Imputation of Missing Data_*](https://stefvanbuuren.name/fimd/) by Stef van Buuren. 


1. Explain the jargon MCAR, MAR, and MNAR.

MCAR the trend that the data missing is completely random

MNAR the trend of missing data is not at random, it is related to the missing values

MAR the trend of missing data is not related to the missing data, but it is related to the observed data.

2. Explain in a couple of sentences how the Multiple Imputation by Chained Equations (MICE) work.

A, B, C column have missing value. First, we use the relationship between A and BC to predict the missing value in A. The we get the missing value in A. Second, using AC to predict B. And then do this for B. 

3. Perform a data quality check of the ICU stays data. Discard variables with substantial missingness, say >5000 `NA`s. Replace apparent data entry errors by `NA`s.

```{r setup, warning=FALSE}
icu_cohort <- readRDS("icu_cohort.rds")
icu_cohort <- as.data.frame(icu_cohort)
#check the extreme outliers in lab and vital data
for (i in 28:42){
  icu_cohort[, i] <- as.numeric(unlist(icu_cohort[, i]))
  outlier_up <- 3 * IQR(icu_cohort[, i],na.rm = TRUE) + 
    quantile(icu_cohort[, i], 3/4, na.rm = TRUE)
  outlier_down <- quantile(icu_cohort[, i], 1/4, na.rm = TRUE) - 
    3 * IQR(icu_cohort[, i],na.rm = TRUE) 
  na1 <- length(which(icu_cohort[, i] >= outlier_up))
  na2 <- length(which(icu_cohort[, i] <= outlier_down))
  na3 <- sum(is.na(icu_cohort[, i])) 
  na <- na1 + na2 + na3
  icu_cohort[ which(icu_cohort[, i] >= outlier_up), i] <- "NA"
   icu_cohort[, i] <- as.numeric(unlist(icu_cohort[, i]))
  icu_cohort[ which(icu_cohort[, i] <= outlier_down), i] <- "NA"
  icu_cohort[, i] <- as.numeric(unlist(icu_cohort[, i]))
  print(na) 
}
```

we can see that all the variable have less than 5000`NA`

4. Impute missing values by `miceRanger` (request $m=3$ data sets). This step is computational intensive. Make sure to save the imputation results as a file. Hint: Setting `max.depth=10` in the `miceRanger` function may cut some computing time.

```{r eval = FALSE}
# select lab, vital, categorical and thirty_day_mort variable
icu_select <- icu_cohort %>% 
  select("gender","age", "marital_status", "ethnicity",
         "lab50971", "lab51301", "lab50882", "lab51221",
         "lab50931", "lab50912", "lab50902", "lab50983",
         "lab50960", "lab50893", "vital220179", "vital220181",
         "vital220210", "vital223761", "vital220045", "thirty_day_mort") 
#change yes and no to 1 and 0
icu_select$thirty_day_mort <- 
  ifelse(icu_select$thirty_day_mort == "Yes", 1, 0)
icu_select %>%  write_rds("icu_cohort_run.rds")
#change character variable to factor
icu_select$gender <- factor(icu_select$gender)
icu_select$marital_status <- factor(icu_select$marital_status)
icu_select$ethnicity <- factor(icu_select$ethnicity)
require(miceRanger)
# impute the missing data
miceObj <- miceRanger(
         icu_select,
         m = 3,
         max.depth = 10,
         returnModels = FALSE)
# write all the three impute dataset
miceObj %>%  write_rds("icu_cohort_mice.rds")
```

5. Make imputation diagnostic plots and explain what they mean.

```{r}
# read impute data
icu_cohort_mice <- readRDS("icu_cohort_mice.rds")
# plot Distribution of Imputed Values
plotDistributions(icu_cohort_mice, vars = 'allNumeric')
```

The red line is the density of the original, nonmissing data. The smaller, black lines are the density of the imputed values in each of the datasets. If these donâ€™t match up, the data may  not be Missing Completely at Random.


```{r}
plotModelError(icu_cohort_mice, vars = 'allNumeric')
```
 The variables were imputed with a reasonable degree of accuracy except lab50983 and vital 220181, vital 223761 and vital 220045.
 
```{r}
plotVarImportance(icu_cohort_mice)
```
 

6. Choose one of the imputed data sets to be used in Q2. This is **not** a good idea to use just one imputed data set or to average multiple imputed data sets. Explain in a couple of sentences what the correct Multiple Imputation strategy is.

```{r}
#select dataset 2
dataList <- completeData(icu_cohort_mice, datasets = 2)
data <- data.frame(dataList)
data %>%  write_rds("icu_cohort_mice2.rds")
```


The first stage is to create multiple copies of the dataset, with the missing values replaced by imputed values.The second stage is to use standard statistical methods to fit the model of interest to each of the imputed datasets
Imputing the mean preserves the mean of the observed data. So if the data are missing completely at random, the estimate of the mean remains unbiased

## Q2. Predicting 30-day mortality

Develop at least two analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression (`glm()` function in base R or keras), (2) logistic regression with lasso penalty (glmnet or keras package), (3) random forest (randomForest package), or (4) neural network (keras package).

1. Partition data into 80% training set and 20% test set. Stratify partitioning according the 30-day mortality status.

2. Train the models using the training set.

3. Compare model prediction performance on the test set.

```{r}
library(pROC)
library(ggplot2)
library(caret)
library(randomForest)
# read icu_cohort_mice2
icu_cohort_mice2 <- readRDS("icu_cohort_mice2.rds")
# change character to factor
icu_cohort_mice2$Dataset_2.gender <-factor(icu_cohort_mice2$Dataset_2.gender)
icu_cohort_mice2$Dataset_2.marital_status <-
  factor(icu_cohort_mice2$Dataset_2.marital_status)
icu_cohort_mice2$Dataset_2.ethnicity <-
  factor(icu_cohort_mice2$Dataset_2.ethnicity)
icu_cohort_mice2$Dataset_2.thirty_day_mort <-
  factor(icu_cohort_mice2$Dataset_2.thirty_day_mort)
#partition
set.seed(100)
intrain <- createDataPartition(y = icu_cohort_mice2$Dataset_2.thirty_day_mort,
                               p = 0.8, list = FALSE)
training <- icu_cohort_mice2[intrain,]
testing <- icu_cohort_mice2[-intrain,]
# run logistic model
model1 <- glm(formula = Dataset_2.thirty_day_mort~. ,
              family = binomial(link = "logit"), data = training)
summary(model1)
# predict 
prob1 <- predict(object = model1, newdata = testing, type = "response")
pred1 <- ifelse(prob1 >= 0.5, "1", "0")
pred1 <- factor(pred1, levels = c("1", "0"), order = TRUE)
testing$Dataset_2.thirty_day_mort <- 
  factor(testing$Dataset_2.thirty_day_mort, order = TRUE)
confusionMatrix(data = as.factor(pred1), 
                reference = as.factor( testing$Dataset_2.thirty_day_mort))
# roc curve
roc_curve <- roc(testing$Dataset_2.thirty_day_mort,prob1)
x <- 1-roc_curve$specificities
y <- roc_curve$sensitivities
p <- ggplot(data = NULL, mapping = aes(x = x, y = y)) +
  geom_line(colour = 'red') +
  geom_abline(intercept = 0, slope = 1)
p
```

```{r}
#random forest
model2 <- randomForest(Dataset_2.thirty_day_mort~., data = training, 
                       ntree = 200, mtry = 5, importance = T)
# predict
predictions <- as.data.frame(predict(model2, testing, type = "prob"))
predictions$predict <- 
  names(predictions)[1:2][apply(predictions[,1:2], 1, which.max)]
pred <- ifelse(predictions$predict == 1, "1", "0")
pred <- factor(pred, levels = c("1", "0"), order = TRUE)

table(testing$Dataset_2.thirty_day_mort, pred)
confusionMatrix(data = as.factor(pred),
                reference = as.factor(testing$Dataset_2.thirty_day_mort))
# roc curve
roc_curve <- roc(testing$Dataset_2.thirty_day_mort, predictions$`1`)
x <- 1-roc_curve$specificities
y <- roc_curve$sensitivities
p <- ggplot(data = NULL, mapping = aes(x = x, y = y)) +
  geom_line(colour = 'red') +
  geom_abline(intercept = 0, slope = 1)
p
```






